{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kelvin3720/CU_CMT316_Coursework_1/blob/main/part_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "31222912-5447-4ea6-8a83-df18945cdf56"
      },
      "outputs": [],
      "source": [
        "import operator\n",
        "import os\n",
        "from typing import List\n",
        "import nltk\n",
        "import numpy as np\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
        "from sklearn.metrics import accuracy_score, precision_score\n",
        "from sklearn.metrics import recall_score, f1_score"
      ],
      "id": "31222912-5447-4ea6-8a83-df18945cdf56"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lkoYDcgMCy5L",
        "outputId": "b73bfa8a-acd9-414f-86d3-5861e63522d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "bbc  bbc.zip  sample_data\n"
          ]
        }
      ],
      "source": [
        "# Please upload the bbc folder first if it does not exist\n",
        "# Do it by uploading the bbc.zip which contains the bbc folder\n",
        "# Then run !unzip bbc.zip\n",
        "!ls"
      ],
      "id": "lkoYDcgMCy5L"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c8f1c68a-6aa7-4589-859e-de58feff7a2f"
      },
      "outputs": [],
      "source": [
        "def show_marco_average_metrics(y_true: List[int], Y_pred: List[int]) -> None:\n",
        "    \"\"\"\n",
        "    Print out the macro-averaged precision,\n",
        "    macro-averaged recall and macro-averaged F1\n",
        "    \"\"\"\n",
        "    precision = precision_score(y_true, y_pred, average='macro')\n",
        "    recall = recall_score(y_true, y_pred, average='macro')\n",
        "    f1 = f1_score(y_true, y_pred, average='macro')\n",
        "\n",
        "    print(\"macro-averaged precision: \", precision)\n",
        "    print(\"macro-averaged recall: \", recall)\n",
        "    print(\"macro-averaged F1: \", f1)\n",
        "\n",
        "    return"
      ],
      "id": "c8f1c68a-6aa7-4589-859e-de58feff7a2f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d6fa3d5c-0466-4a9a-a522-38466d6a9dec"
      },
      "outputs": [],
      "source": [
        "# Please put the bbc folder at the same location with this part_2.ipynb file\n",
        "folders = [\"business\", \"entertainment\", \"politics\", \"sport\", \"tech\"]\n",
        "cwd = os.getcwd()\n",
        "path = os.path.join(cwd, \"bbc\")\n",
        "# Unprocessed data, index 0 is the txext, 1 is the categories\n",
        "# 0: business; 1: entertainment; 2:politics; 3: sport; 4: tech\n",
        "raw_data = []\n",
        "\n",
        "# Write the data into row_data\n",
        "for index, folder in enumerate(folders):\n",
        "    folder_path = os.path.join(path, folder)\n",
        "    for file_name in os.listdir(folder_path):\n",
        "        file_path = os.path.join(folder_path, file_name)\n",
        "        # There are a little bit characters cannot decode,\n",
        "        # so errors='ignore' is used\n",
        "        with open(file_path, 'r', encoding='utf-8', errors='ignore') as file:\n",
        "            raw_data.append([file.read(), index])"
      ],
      "id": "d6fa3d5c-0466-4a9a-a522-38466d6a9dec"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1d9cddf5-434a-4e96-9bb9-b6d227d47c82"
      },
      "outputs": [],
      "source": [
        "## Data processing\n",
        "\n",
        "# Code from live class sessions, 2_FeatureEngineeringSelection_Sklearn.ipynb\n",
        "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
        "\n",
        "def get_list_tokens(string):\n",
        "  sentence_split=nltk.tokenize.sent_tokenize(string)\n",
        "  list_tokens=[]\n",
        "  for sentence in sentence_split:\n",
        "    list_tokens_sentence=nltk.tokenize.word_tokenize(sentence)\n",
        "    for token in list_tokens_sentence:\n",
        "      list_tokens.append(lemmatizer.lemmatize(token).lower())\n",
        "  return list_tokens"
      ],
      "id": "1d9cddf5-434a-4e96-9bb9-b6d227d47c82"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dcaa19b8-e86e-4074-b566-b441f2af348c",
        "outputId": "f6026289-7117-4df7-d5a8-7cc1627794a6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "stopwords = set(nltk.corpus.stopwords.words('english'))\n",
        "stopwords.add(\".\")\n",
        "stopwords.add(\",\")\n",
        "stopwords.add(\"--\")\n",
        "stopwords.add(\"``\")"
      ],
      "id": "dcaa19b8-e86e-4074-b566-b441f2af348c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44f5d05f-2830-440b-aaf5-5afa8501d78b",
        "outputId": "78169704-cba4-493f-f0b3-124519100ffe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1. '' - 9296\n",
            "2. 's - 8895\n",
            "3. said - 7253\n",
            "4. wa - 6088\n",
            "5. ha - 4971\n",
            "6. - - 3197\n",
            "7. mr - 2994\n",
            "8. year - 2824\n",
            "9. would - 2629\n",
            "10. ) - 2229\n",
            "11. ( - 2227\n",
            "12. also - 2156\n",
            "13. people - 2045\n",
            "14. % - 1968\n",
            "15. new - 1966\n",
            "16. one - 1806\n",
            "17. us - 1673\n",
            "18. : - 1667\n",
            "19. could - 1546\n",
            "20. game - 1401\n",
            "21. last - 1380\n",
            "22. time - 1361\n",
            "23. first - 1283\n",
            "24. say - 1265\n",
            "25. n't - 1258\n"
          ]
        }
      ],
      "source": [
        "dict_word_frequency={}\n",
        "\n",
        "for entry in raw_data:\n",
        "    sentence_tokens=get_list_tokens(entry[0])\n",
        "    for word in sentence_tokens:\n",
        "        if word in stopwords: continue\n",
        "        if word not in dict_word_frequency: dict_word_frequency[word]=1\n",
        "        else: dict_word_frequency[word]+=1\n",
        "\n",
        "sorted_list = sorted(\n",
        "    dict_word_frequency.items(), key=operator.itemgetter(1), reverse=True\n",
        "    )[:1000]\n",
        "i=0\n",
        "for word,frequency in sorted_list[:25]:\n",
        "  i+=1\n",
        "  print (str(i)+\". \"+word+\" - \"+str(frequency))\n",
        "\n",
        "vocabulary=[]\n",
        "for word,frequency in sorted_list:\n",
        "  vocabulary.append(word)"
      ],
      "id": "44f5d05f-2830-440b-aaf5-5afa8501d78b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c2d51b4a-461b-408c-a109-dd8f6c229c36"
      },
      "outputs": [],
      "source": [
        "def get_vector_text(list_vocab,string):\n",
        "  vector_text=np.zeros(len(list_vocab))\n",
        "  list_tokens_string=get_list_tokens(string)\n",
        "  for i, word in enumerate(list_vocab):\n",
        "    if word in list_tokens_string:\n",
        "      vector_text[i]=list_tokens_string.count(word)\n",
        "  return vector_text"
      ],
      "id": "c2d51b4a-461b-408c-a109-dd8f6c229c36"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3c0734e1-677b-43c3-b223-8aed3a97397d"
      },
      "outputs": [],
      "source": [
        "## With only word frequency as feature\n",
        "x_all=[]\n",
        "y_all=[]\n",
        "\n",
        "for entry in raw_data:\n",
        "    # Feature 1: Word frequency\n",
        "    vector_pos=get_vector_text(vocabulary, entry[0])\n",
        "    x_all.append(vector_pos)\n",
        "    y_all.append(entry[1])"
      ],
      "id": "3c0734e1-677b-43c3-b223-8aed3a97397d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "70887c8d-00fd-4573-b1ff-955dd5127aa1"
      },
      "outputs": [],
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x_all, y_all, test_size=0.4)"
      ],
      "id": "70887c8d-00fd-4573-b1ff-955dd5127aa1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7d76e3c1-e352-4e82-b0e1-4d1b1f257a39"
      },
      "outputs": [],
      "source": [
        "x_train_sentanalysis = np.asarray(x_train)\n",
        "y_train_sentanalysis = np.asarray(y_train)\n",
        "x_test = np.asarray(x_test)\n",
        "y_test = np.asarray(y_test)"
      ],
      "id": "7d76e3c1-e352-4e82-b0e1-4d1b1f257a39"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0a008ac-e9ff-4f9c-b4e3-1fe0b5561a97",
        "outputId": "a45dc823-8e6d-4e43-d219-67a23907c163"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Size original training matrix: (1335, 1000)\n",
            "Size new training matrix: (1335, 500)\n"
          ]
        }
      ],
      "source": [
        "# Feature selection\n",
        "from sklearn.feature_selection import chi2\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "\n",
        "fs_sentanalysis=SelectKBest(\n",
        "    chi2, k=500\n",
        "    ).fit(x_train_sentanalysis, y_train_sentanalysis)\n",
        "x_train_sentanalysis_new = fs_sentanalysis.transform(x_train_sentanalysis)\n",
        "x_test_new = fs_sentanalysis.transform(x_test)\n",
        "print (\"Size original training matrix: \"+str(x_train_sentanalysis.shape))\n",
        "print (\"Size new training matrix: \"+str(x_train_sentanalysis_new.shape))"
      ],
      "id": "f0a008ac-e9ff-4f9c-b4e3-1fe0b5561a97"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "d0bce0f9-28f8-4a44-a30c-6b1696c04b6c",
        "outputId": "65adb1b3-5d5e-47af-de42-53ea1c1e706b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(gamma=&#x27;auto&#x27;, kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(gamma=&#x27;auto&#x27;, kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "SVC(gamma='auto', kernel='linear')"
            ]
          },
          "execution_count": 107,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = sklearn.svm.SVC(kernel=\"linear\",gamma='auto')\n",
        "model.fit(x_train_sentanalysis_new,y_train_sentanalysis)"
      ],
      "id": "d0bce0f9-28f8-4a44-a30c-6b1696c04b6c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "944a2819-565f-42a0-8f33-9bfc1134c707",
        "outputId": "5af79393-e5a7-4f81-c04f-7e1286fb1d89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9561797752808989\n"
          ]
        }
      ],
      "source": [
        "y_pred = model.predict(x_test_new)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "id": "944a2819-565f-42a0-8f33-9bfc1134c707"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2f1cff9-515f-4f13-b1fd-2774ee8a2f08",
        "outputId": "dbe72b22-bb5d-493a-821e-45991bbb97c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "K-fold Results: [0.96412556 0.95964126 0.98206278 0.96860987 0.96412556 0.95945946\n",
            " 0.95945946 0.94144144 0.95945946 0.97297297]\n",
            "Mean Accuracy: 0.9631357815214319\n"
          ]
        }
      ],
      "source": [
        "kf = KFold(n_splits=10, shuffle=True)\n",
        "cross_val_results = cross_val_score(model, x_all, y_all, cv=kf)\n",
        "\n",
        "print(f\"K-fold Results: {cross_val_results}\")\n",
        "print(f\"Mean Accuracy: {np.mean(cross_val_results)}\")"
      ],
      "id": "f2f1cff9-515f-4f13-b1fd-2774ee8a2f08"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97861bb4-781e-4c6b-9809-b75e2831c0e2",
        "outputId": "a8ec9cca-6550-45c7-ebca-f892dbb66244"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "macro-averaged precision:  0.9584351412851945\n",
            "macro-averaged recall:  0.9543280013503226\n",
            "macro-averaged F1:  0.9561604182685943\n"
          ]
        }
      ],
      "source": [
        "show_marco_average_metrics(y_test, y_pred)"
      ],
      "id": "97861bb4-781e-4c6b-9809-b75e2831c0e2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "dda5be07-8005-46b9-94c4-692721cbc138",
        "outputId": "89eaa6c8-5504-4372-b15a-0760582fe78c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Word count feature is already selected by SelectKBest()\n",
            "Size original training matrix: (1335, 1001)\n",
            "Size new training matrix: (1335, 500)\n"
          ]
        }
      ],
      "source": [
        "## Added Word count of the text file as second feature\n",
        "x_all=[]\n",
        "y_all=[]\n",
        "\n",
        "for entry in raw_data:\n",
        "    # Feature 1: Word frequency\n",
        "    vector_pos=get_vector_text(vocabulary, entry[0])\n",
        "    # Feature 2: Word count of the text file\n",
        "    word_count = len(get_list_tokens(entry[0]))\n",
        "    features = np.append(vector_pos, word_count)\n",
        "    x_all.append(features)\n",
        "    y_all.append(entry[1])\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    x_all, y_all, test_size=0.4\n",
        "    )\n",
        "\n",
        "x_train_sentanalysis = np.asarray(x_train)\n",
        "y_train_sentanalysis = np.asarray(y_train)\n",
        "x_test = np.asarray(x_test)\n",
        "y_test = np.asarray(y_test)\n",
        "\n",
        "fs_sentanalysis=SelectKBest(\n",
        "    chi2, k=500\n",
        "    ).fit(x_train_sentanalysis, y_train_sentanalysis)\n",
        "\n",
        "# Force keep the manually added features\n",
        "selected_indices = fs_sentanalysis.get_support(indices=True)\n",
        "if 1000 not in selected_indices:\n",
        "    print(\"Adding the word count feature\")\n",
        "    selected_indices = np.concatenate([selected_indices, [1000]])\n",
        "else:\n",
        "    print(\"Word count feature is already selected by SelectKBest()\")\n",
        "\n",
        "x_train_sentanalysis_new = x_train_sentanalysis[:, selected_indices]\n",
        "x_test_new = x_test[:, selected_indices]\n",
        "\n",
        "print (\"Size original training matrix: \"+str(x_train_sentanalysis.shape))\n",
        "print (\"Size new training matrix: \"+str(x_train_sentanalysis_new.shape))"
      ],
      "id": "dda5be07-8005-46b9-94c4-692721cbc138"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "44c58fdd-c72d-45ad-bf8b-191149f8c68e",
        "outputId": "375587e4-98e5-41ca-8c45-5d47d824d9e3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(gamma=&#x27;auto&#x27;, kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(gamma=&#x27;auto&#x27;, kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "SVC(gamma='auto', kernel='linear')"
            ]
          },
          "execution_count": 112,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = sklearn.svm.SVC(kernel=\"linear\",gamma='auto')\n",
        "model.fit(x_train_sentanalysis_new,y_train_sentanalysis)"
      ],
      "id": "44c58fdd-c72d-45ad-bf8b-191149f8c68e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "cb1815ae-d695-4b56-a582-32e7d540f583",
        "outputId": "cbce2412-7e1d-4a23-cbc9-a23b97c030de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9415730337078652\n"
          ]
        }
      ],
      "source": [
        "y_pred = model.predict(x_test_new)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "id": "cb1815ae-d695-4b56-a582-32e7d540f583"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "81cc9abf-3600-4e26-ac8e-3bab3fb58a86",
        "outputId": "3346f4a6-c6ec-4931-d47a-6c278f52bf30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "K-fold Results: [0.96412556 0.95515695 0.97757848 0.92825112 0.97757848 0.95945946\n",
            " 0.94144144 0.96396396 0.95945946 0.93693694]\n",
            "Mean Accuracy: 0.95639518442209\n"
          ]
        }
      ],
      "source": [
        "kf = KFold(n_splits=10, shuffle=True)\n",
        "cross_val_results = cross_val_score(model, x_all, y_all, cv=kf)\n",
        "\n",
        "print(f\"K-fold Results: {cross_val_results}\")\n",
        "print(f\"Mean Accuracy: {np.mean(cross_val_results)}\")"
      ],
      "id": "81cc9abf-3600-4e26-ac8e-3bab3fb58a86"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "755d3525-12f8-4690-9b26-f052461632fa",
        "outputId": "eb69fca2-79d5-4b4b-8dc2-bff70e715e70"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "macro-averaged precision:  0.9424743379013758\n",
            "macro-averaged recall:  0.9398601452078157\n",
            "macro-averaged F1:  0.9407663972383599\n"
          ]
        }
      ],
      "source": [
        "show_marco_average_metrics(y_test, y_pred)"
      ],
      "id": "755d3525-12f8-4690-9b26-f052461632fa"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9c9f3b87-1174-49c9-8d14-7810f56c6333",
        "outputId": "ab641cb6-e22a-4567-ba3c-046342aadbae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('CARDINAL', 'DATE', 'EVENT', 'FAC', 'GPE', 'LANGUAGE', 'LAW', 'LOC', 'MONEY', 'NORP', 'ORDINAL', 'ORG', 'PERCENT', 'PERSON', 'PRODUCT', 'QUANTITY', 'TIME', 'WORK_OF_ART')\n"
          ]
        }
      ],
      "source": [
        "## Added Named Entity recognition as the thrid feature\n",
        "\n",
        "import spacy\n",
        "\n",
        "\"\"\"\n",
        "Please run\n",
        "python -m spacy download en\n",
        "if you don't have en_core_web_sm\n",
        "\"\"\"\n",
        "# English NLP model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "ner_labels = nlp.get_pipe(\"ner\").labels\n",
        "print(ner_labels) # Possible labels"
      ],
      "id": "9c9f3b87-1174-49c9-8d14-7810f56c6333"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "237aeef6-ac4f-4ac1-9346-7a24c1d3b405"
      },
      "outputs": [],
      "source": [
        "def count_entity(text: str) -> List[int]:\n",
        "    \"\"\"\n",
        "    Count the occurance of the following selected labels in the input text:\n",
        "    GPE (locations, like city anc country),\n",
        "    LAW,\n",
        "    MONEY,\n",
        "    ORG,\n",
        "    PRODUCT,\n",
        "    WORK_OF_ART\n",
        "    Which will be in corrosponding index from 0 to 5\n",
        "    \"\"\"\n",
        "    useful_labels = ['GPE', 'MONEY', 'ORG', 'PRODUCT', 'WORK_OF_ART']\n",
        "    count = {label: 0 for label in useful_labels}\n",
        "    doc = nlp(text)\n",
        "\n",
        "    for ent in doc.ents:\n",
        "        if ent.label_ in useful_labels:\n",
        "            count[ent.label_] += 1\n",
        "\n",
        "    # Convert to List[int] and return\n",
        "    return [count[label] for label in useful_labels]"
      ],
      "id": "237aeef6-ac4f-4ac1-9346-7a24c1d3b405"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "69d2409e-4424-47c3-ae95-c2df6697986c"
      },
      "outputs": [],
      "source": [
        "x_all=[]\n",
        "y_all=[]\n",
        "\n",
        "for entry in raw_data:\n",
        "    # Feature 1: Word frequency\n",
        "    vector_pos=get_vector_text(vocabulary, entry[0])\n",
        "    # Feature 2: Word count of the text file\n",
        "    word_count = len(get_list_tokens(entry[0]))\n",
        "    features = np.append(vector_pos, word_count)\n",
        "    # Feature 3: Named Entity recognition label count\n",
        "    entity_count = count_entity(entry[0])\n",
        "    features = np.append(features, entity_count)\n",
        "    x_all.append(features)\n",
        "    y_all.append(entry[1])"
      ],
      "id": "69d2409e-4424-47c3-ae95-c2df6697986c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "32dd98f4-613f-49b4-9d3b-bc81695afdca",
        "outputId": "2304566d-63af-41f2-9608-7761198925b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Feature index 1000 is already selected by SelectKBest()\n",
            "Feature index 1001 is already selected by SelectKBest()\n",
            "Feature index 1002 is already selected by SelectKBest()\n",
            "Feature index 1003 is already selected by SelectKBest()\n",
            "Feature index 1004 is already selected by SelectKBest()\n",
            "Feature index 1005 is already selected by SelectKBest()\n",
            "Size original training matrix: (1335, 1006)\n",
            "Size new training matrix: (1335, 500)\n"
          ]
        }
      ],
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    x_all, y_all, test_size=0.4\n",
        "    )\n",
        "\n",
        "x_train_sentanalysis = np.asarray(x_train)\n",
        "y_train_sentanalysis = np.asarray(y_train)\n",
        "x_test = np.asarray(x_test)\n",
        "y_test = np.asarray(y_test)\n",
        "\n",
        "fs_sentanalysis=SelectKBest(\n",
        "    chi2, k=500\n",
        "    ).fit(x_train_sentanalysis, y_train_sentanalysis)\n",
        "\n",
        "# Force keep the manually added features\n",
        "selected_indices = fs_sentanalysis.get_support(indices=True)\n",
        "\n",
        "for i in range(1000, 1006):\n",
        "    if i not in selected_indices:\n",
        "        print(f\"Adding the feature with index {str(i)}\")\n",
        "        selected_indices = np.concatenate([selected_indices, [i]])\n",
        "    else:\n",
        "        print(f\"Feature index {str(i)} is already selected by SelectKBest()\")\n",
        "\n",
        "x_train_sentanalysis_new = x_train_sentanalysis[:, selected_indices]\n",
        "x_test_new = x_test[:, selected_indices]\n",
        "\n",
        "print (\"Size original training matrix: \"+str(x_train_sentanalysis.shape))\n",
        "print (\"Size new training matrix: \"+str(x_train_sentanalysis_new.shape))"
      ],
      "id": "32dd98f4-613f-49b4-9d3b-bc81695afdca"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "95de4f5c-b4d1-423c-9a19-a51a97408e6d",
        "outputId": "1f05957f-ca88-4d86-c542-eed649cbd016"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-9 {color: black;background-color: white;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(gamma=&#x27;auto&#x27;, kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" checked><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(gamma=&#x27;auto&#x27;, kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "SVC(gamma='auto', kernel='linear')"
            ]
          },
          "execution_count": 120,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = sklearn.svm.SVC(kernel=\"linear\",gamma='auto')\n",
        "model.fit(x_train_sentanalysis_new,y_train_sentanalysis)"
      ],
      "id": "95de4f5c-b4d1-423c-9a19-a51a97408e6d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9cc30827-b8f3-4545-bff9-fb909f92b29a",
        "outputId": "1dca8284-4c38-4db6-ca94-1d9619dd514a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9516853932584269\n"
          ]
        }
      ],
      "source": [
        "y_pred = model.predict(x_test_new)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "id": "9cc30827-b8f3-4545-bff9-fb909f92b29a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "4d271a41-de00-44c3-ab91-11d2244ae31b",
        "outputId": "94419375-d765-44e4-a218-b3bae9a11d06"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "K-fold Results: [0.94618834 0.95067265 0.96412556 0.94618834 0.97309417 0.96846847\n",
            " 0.96846847 0.95495495 0.93693694 0.96846847]\n",
            "Mean Accuracy: 0.9577566355593261\n"
          ]
        }
      ],
      "source": [
        "kf = KFold(n_splits=10, shuffle=True)\n",
        "cross_val_results = cross_val_score(model, x_all, y_all, cv=kf)\n",
        "\n",
        "print(f\"K-fold Results: {cross_val_results}\")\n",
        "print(f\"Mean Accuracy: {np.mean(cross_val_results)}\")"
      ],
      "id": "4d271a41-de00-44c3-ab91-11d2244ae31b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "84d402e4-4036-49ca-953d-b7f6e3a3a635",
        "outputId": "6eccc3d2-5b42-430c-93ce-028db37e5dd4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "macro-averaged precision:  0.9523152028956984\n",
            "macro-averaged recall:  0.9506877360310991\n",
            "macro-averaged F1:  0.9513660760459995\n"
          ]
        }
      ],
      "source": [
        "show_marco_average_metrics(y_test, y_pred)"
      ],
      "id": "84d402e4-4036-49ca-953d-b7f6e3a3a635"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}