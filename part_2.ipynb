{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kelvin3720/CU_CMT316_Coursework_1/blob/main/part_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialisation"
      ],
      "metadata": {
        "id": "nVtl4vcf900F"
      },
      "id": "nVtl4vcf900F"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "31222912-5447-4ea6-8a83-df18945cdf56",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "853194be-0b0b-472d-a53d-8b093551a781"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import operator\n",
        "import os\n",
        "from typing import List\n",
        "import nltk\n",
        "import numpy as np\n",
        "import spacy\n",
        "import sklearn\n",
        "from sklearn.feature_selection import chi2\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.metrics import accuracy_score, precision_score\n",
        "from sklearn.metrics import recall_score, f1_score\n",
        "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "stopwords = set(nltk.corpus.stopwords.words('english'))\n",
        "stopwords.add(\".\")\n",
        "stopwords.add(\",\")\n",
        "stopwords.add(\"--\")\n",
        "stopwords.add(\"``\")\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "id": "31222912-5447-4ea6-8a83-df18945cdf56"
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lkoYDcgMCy5L",
        "outputId": "8a5118dc-edc4-46a6-bf8b-ba99b4ec080a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bbc  bbc.zip  sample_data\n"
          ]
        }
      ],
      "source": [
        "# Please upload the bbc folder first if it does not exist\n",
        "# Do it by uploading the bbc.zip which contains the bbc folder\n",
        "# Then run !unzip bbc.zip\n",
        "!ls"
      ],
      "id": "lkoYDcgMCy5L"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Helper functions"
      ],
      "metadata": {
        "id": "8ViL-BxO9sH-"
      },
      "id": "8ViL-BxO9sH-"
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "c8f1c68a-6aa7-4589-859e-de58feff7a2f"
      },
      "outputs": [],
      "source": [
        "def show_marco_average_metrics(y_true: List[int], Y_pred: List[int]) -> None:\n",
        "  \"\"\"\n",
        "  Print out the macro-averaged precision,\n",
        "  macro-averaged recall and macro-averaged F1\n",
        "  \"\"\"\n",
        "  precision = precision_score(y_true, y_pred, average='macro')\n",
        "  recall = recall_score(y_true, y_pred, average='macro')\n",
        "  f1 = f1_score(y_true, y_pred, average='macro')\n",
        "\n",
        "  print(\"macro-averaged precision: \", precision)\n",
        "  print(\"macro-averaged recall: \", recall)\n",
        "  print(\"macro-averaged F1: \", f1)\n",
        "\n",
        "\n",
        "def get_list_tokens(string: str) -> List[str]:\n",
        "  lemmatizer = nltk.stem.WordNetLemmatizer()\n",
        "  sentence_split=nltk.tokenize.sent_tokenize(string)\n",
        "  list_tokens=[]\n",
        "  for sentence in sentence_split:\n",
        "    list_tokens_sentence=nltk.tokenize.word_tokenize(sentence)\n",
        "    for token in list_tokens_sentence:\n",
        "      list_tokens.append(lemmatizer.lemmatize(token).lower())\n",
        "  return list_tokens\n",
        "\n",
        "\n",
        "def get_vector_text(list_vocab: List[str], string: str):\n",
        "  vector_text=np.zeros(len(list_vocab))\n",
        "  list_tokens_string=get_list_tokens(string)\n",
        "  for i, word in enumerate(list_vocab):\n",
        "    if word in list_tokens_string:\n",
        "      vector_text[i]=list_tokens_string.count(word)\n",
        "  return vector_text\n",
        "\n",
        "def count_entity(text: str) -> List[int]:\n",
        "  \"\"\"\n",
        "  Count the occurance of the following selected labels in the input text:\n",
        "  GPE (locations, like city anc country),\n",
        "  LAW,\n",
        "  MONEY,\n",
        "  ORG,\n",
        "  PRODUCT,\n",
        "  WORK_OF_ART\n",
        "  Which will be in corrosponding index from 0 to 5\n",
        "  \"\"\"\n",
        "  # English NLP model\n",
        "  useful_labels = ['GPE', 'MONEY', 'ORG', 'PRODUCT', 'WORK_OF_ART']\n",
        "  count = {label: 0 for label in useful_labels}\n",
        "  doc = nlp(text)\n",
        "\n",
        "  for ent in doc.ents:\n",
        "    if ent.label_ in useful_labels:\n",
        "      count[ent.label_] += 1\n",
        "\n",
        "  # Convert to List[int] and return\n",
        "  return [count[label] for label in useful_labels]"
      ],
      "id": "c8f1c68a-6aa7-4589-859e-de58feff7a2f"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loadind the data"
      ],
      "metadata": {
        "id": "Yr_I2SJT_LgS"
      },
      "id": "Yr_I2SJT_LgS"
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "d6fa3d5c-0466-4a9a-a522-38466d6a9dec"
      },
      "outputs": [],
      "source": [
        "# Please put the bbc folder at the same location with this part_2.ipynb file\n",
        "folders = [\"business\", \"entertainment\", \"politics\", \"sport\", \"tech\"]\n",
        "cwd = os.getcwd()\n",
        "path = os.path.join(cwd, \"bbc\")\n",
        "# Unprocessed data, index 0 is the txext, 1 is the categories\n",
        "# 0: business; 1: entertainment; 2:politics; 3: sport; 4: tech\n",
        "raw_data = []\n",
        "\n",
        "# Write the data into row_data\n",
        "for index, folder in enumerate(folders):\n",
        "    folder_path = os.path.join(path, folder)\n",
        "    for file_name in os.listdir(folder_path):\n",
        "        file_path = os.path.join(folder_path, file_name)\n",
        "        # There are a little bit characters cannot be decoded,\n",
        "        # so errors='ignore' is used\n",
        "        with open(file_path, 'r', encoding='utf-8', errors='ignore') as file:\n",
        "            raw_data.append([file.read(), index])"
      ],
      "id": "d6fa3d5c-0466-4a9a-a522-38466d6a9dec"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data processing"
      ],
      "metadata": {
        "id": "QuxY2drP_NoL"
      },
      "id": "QuxY2drP_NoL"
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44f5d05f-2830-440b-aaf5-5afa8501d78b",
        "outputId": "9579d629-754c-44b7-d31d-e8d21070438b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. '' - 9296\n",
            "2. 's - 8895\n",
            "3. said - 7253\n",
            "4. wa - 6088\n",
            "5. ha - 4971\n",
            "6. - - 3197\n",
            "7. mr - 2994\n",
            "8. year - 2824\n",
            "9. would - 2629\n",
            "10. ) - 2229\n",
            "11. ( - 2227\n",
            "12. also - 2156\n",
            "13. people - 2045\n",
            "14. % - 1968\n",
            "15. new - 1966\n",
            "16. one - 1806\n",
            "17. us - 1673\n",
            "18. : - 1667\n",
            "19. could - 1546\n",
            "20. game - 1401\n",
            "21. last - 1380\n",
            "22. time - 1361\n",
            "23. first - 1283\n",
            "24. say - 1265\n",
            "25. n't - 1258\n"
          ]
        }
      ],
      "source": [
        "dict_word_frequency={}\n",
        "\n",
        "for entry in raw_data:\n",
        "    sentence_tokens=get_list_tokens(entry[0])\n",
        "    for word in sentence_tokens:\n",
        "        if word in stopwords: continue\n",
        "        if word not in dict_word_frequency: dict_word_frequency[word]=1\n",
        "        else: dict_word_frequency[word]+=1\n",
        "\n",
        "sorted_list = sorted(\n",
        "    dict_word_frequency.items(), key=operator.itemgetter(1), reverse=True\n",
        "    )[:1000]\n",
        "i=0\n",
        "for word,frequency in sorted_list[:25]:\n",
        "  i+=1\n",
        "  print (str(i)+\". \"+word+\" - \"+str(frequency))\n",
        "\n",
        "vocabulary=[]\n",
        "for word,frequency in sorted_list:\n",
        "  vocabulary.append(word)"
      ],
      "id": "44f5d05f-2830-440b-aaf5-5afa8501d78b"
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "3c0734e1-677b-43c3-b223-8aed3a97397d"
      },
      "outputs": [],
      "source": [
        "## With only word frequency as feature\n",
        "x_all=[]\n",
        "y_all=[]\n",
        "\n",
        "for entry in raw_data:\n",
        "  # Feature 1: Word frequency\n",
        "  vector_pos=get_vector_text(vocabulary, entry[0])\n",
        "  x_all.append(vector_pos)\n",
        "  y_all.append(entry[1])"
      ],
      "id": "3c0734e1-677b-43c3-b223-8aed3a97397d"
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "70887c8d-00fd-4573-b1ff-955dd5127aa1"
      },
      "outputs": [],
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x_all, y_all, test_size=0.4)"
      ],
      "id": "70887c8d-00fd-4573-b1ff-955dd5127aa1"
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "7d76e3c1-e352-4e82-b0e1-4d1b1f257a39"
      },
      "outputs": [],
      "source": [
        "x_train_sentanalysis = np.asarray(x_train)\n",
        "y_train_sentanalysis = np.asarray(y_train)\n",
        "x_test = np.asarray(x_test)\n",
        "y_test = np.asarray(y_test)"
      ],
      "id": "7d76e3c1-e352-4e82-b0e1-4d1b1f257a39"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature selection"
      ],
      "metadata": {
        "id": "GNcDKhxf_3mY"
      },
      "id": "GNcDKhxf_3mY"
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0a008ac-e9ff-4f9c-b4e3-1fe0b5561a97",
        "outputId": "d01bf6ae-2697-4ccf-fe81-1a53325dad2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size original training matrix: (1335, 1000)\n",
            "Size new training matrix: (1335, 500)\n"
          ]
        }
      ],
      "source": [
        "fs_sentanalysis=SelectKBest(\n",
        "    chi2, k=500\n",
        "    ).fit(x_train_sentanalysis, y_train_sentanalysis)\n",
        "x_train_sentanalysis_new = fs_sentanalysis.transform(x_train_sentanalysis)\n",
        "x_test_new = fs_sentanalysis.transform(x_test)\n",
        "print (\"Size original training matrix: \"+str(x_train_sentanalysis.shape))\n",
        "print (\"Size new training matrix: \"+str(x_train_sentanalysis_new.shape))"
      ],
      "id": "f0a008ac-e9ff-4f9c-b4e3-1fe0b5561a97"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training and Predicting (1 Feature only)"
      ],
      "metadata": {
        "id": "5zPTpMvMADuG"
      },
      "id": "5zPTpMvMADuG"
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "d0bce0f9-28f8-4a44-a30c-6b1696c04b6c",
        "outputId": "f465198f-4727-4e48-f3e4-f53a314e50cd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(gamma='auto', kernel='linear')"
            ],
            "text/html": [
              "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(gamma=&#x27;auto&#x27;, kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(gamma=&#x27;auto&#x27;, kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "model = sklearn.svm.SVC(kernel=\"linear\",gamma='auto')\n",
        "model.fit(x_train_sentanalysis_new,y_train_sentanalysis)"
      ],
      "id": "d0bce0f9-28f8-4a44-a30c-6b1696c04b6c"
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "944a2819-565f-42a0-8f33-9bfc1134c707",
        "outputId": "21077059-ccb3-4636-b3ab-81fbb8a226e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9561797752808989\n"
          ]
        }
      ],
      "source": [
        "y_pred = model.predict(x_test_new)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "id": "944a2819-565f-42a0-8f33-9bfc1134c707"
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2f1cff9-515f-4f13-b1fd-2774ee8a2f08",
        "outputId": "2b18289d-a3c2-49b9-a10e-57a7eee683bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "K-fold Results: [0.97309417 0.95067265 0.96412556 0.96412556 0.95964126 0.96846847\n",
            " 0.93693694 0.94594595 0.96846847 0.96396396]\n",
            "Mean Accuracy: 0.9595442976608897\n"
          ]
        }
      ],
      "source": [
        "kf = KFold(n_splits=10, shuffle=True)\n",
        "cross_val_results = cross_val_score(model, x_all, y_all, cv=kf)\n",
        "\n",
        "print(f\"K-fold Results: {cross_val_results}\")\n",
        "print(f\"Mean Accuracy: {np.mean(cross_val_results)}\")"
      ],
      "id": "f2f1cff9-515f-4f13-b1fd-2774ee8a2f08"
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97861bb4-781e-4c6b-9809-b75e2831c0e2",
        "outputId": "e984ab71-e2f0-4369-c1f2-f1df42a931db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "macro-averaged precision:  0.9570302192048622\n",
            "macro-averaged recall:  0.9576484616716145\n",
            "macro-averaged F1:  0.95717297106359\n"
          ]
        }
      ],
      "source": [
        "show_marco_average_metrics(y_test, y_pred)"
      ],
      "id": "97861bb4-781e-4c6b-9809-b75e2831c0e2"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data processing and Feature selection (Adding seond feature)"
      ],
      "metadata": {
        "id": "vRXI08YfAKIF"
      },
      "id": "vRXI08YfAKIF"
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dda5be07-8005-46b9-94c4-692721cbc138",
        "outputId": "4ac6b9bd-9d81-443f-82a0-322f8948935c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word count feature is already selected by SelectKBest()\n",
            "Size original training matrix: (1335, 1001)\n",
            "Size new training matrix: (1335, 500)\n"
          ]
        }
      ],
      "source": [
        "## Added Word count of the text file as second feature\n",
        "x_all=[]\n",
        "y_all=[]\n",
        "\n",
        "for entry in raw_data:\n",
        "    # Feature 1: Word frequency\n",
        "    vector_pos=get_vector_text(vocabulary, entry[0])\n",
        "    # Feature 2: Word count of the text file\n",
        "    word_count = len(get_list_tokens(entry[0]))\n",
        "    features = np.append(vector_pos, word_count)\n",
        "    x_all.append(features)\n",
        "    y_all.append(entry[1])\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    x_all, y_all, test_size=0.4\n",
        "    )\n",
        "\n",
        "x_train_sentanalysis = np.asarray(x_train)\n",
        "y_train_sentanalysis = np.asarray(y_train)\n",
        "x_test = np.asarray(x_test)\n",
        "y_test = np.asarray(y_test)\n",
        "\n",
        "fs_sentanalysis=SelectKBest(\n",
        "    chi2, k=500\n",
        "    ).fit(x_train_sentanalysis, y_train_sentanalysis)\n",
        "\n",
        "# Force keep the manually added features\n",
        "selected_indices = fs_sentanalysis.get_support(indices=True)\n",
        "if 1000 not in selected_indices:\n",
        "    print(\"Adding the word count feature\")\n",
        "    selected_indices = np.concatenate([selected_indices, [1000]])\n",
        "else:\n",
        "    print(\"Word count feature is already selected by SelectKBest()\")\n",
        "\n",
        "x_train_sentanalysis_new = x_train_sentanalysis[:, selected_indices]\n",
        "x_test_new = x_test[:, selected_indices]\n",
        "\n",
        "print (\"Size original training matrix: \"+str(x_train_sentanalysis.shape))\n",
        "print (\"Size new training matrix: \"+str(x_train_sentanalysis_new.shape))"
      ],
      "id": "dda5be07-8005-46b9-94c4-692721cbc138"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training and predicting (With 2 features)"
      ],
      "metadata": {
        "id": "7J_Nhg-9AuB1"
      },
      "id": "7J_Nhg-9AuB1"
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "44c58fdd-c72d-45ad-bf8b-191149f8c68e",
        "outputId": "48c4ab65-104f-4086-a725-3934d00272cc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(gamma='auto', kernel='linear')"
            ],
            "text/html": [
              "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(gamma=&#x27;auto&#x27;, kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(gamma=&#x27;auto&#x27;, kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "model = sklearn.svm.SVC(kernel=\"linear\",gamma='auto')\n",
        "model.fit(x_train_sentanalysis_new,y_train_sentanalysis)"
      ],
      "id": "44c58fdd-c72d-45ad-bf8b-191149f8c68e"
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cb1815ae-d695-4b56-a582-32e7d540f583",
        "outputId": "cdd3d540-6915-4279-9c7d-c12e38a86bf9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9449438202247191\n"
          ]
        }
      ],
      "source": [
        "y_pred = model.predict(x_test_new)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "id": "cb1815ae-d695-4b56-a582-32e7d540f583"
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81cc9abf-3600-4e26-ac8e-3bab3fb58a86",
        "outputId": "d9074017-7bd1-44a7-a8b1-99339aca3395"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "K-fold Results: [0.96860987 0.94618834 0.95515695 0.97309417 0.95067265 0.95945946\n",
            " 0.94594595 0.94144144 0.95495495 0.97747748]\n",
            "Mean Accuracy: 0.9573001252373448\n"
          ]
        }
      ],
      "source": [
        "kf = KFold(n_splits=10, shuffle=True)\n",
        "cross_val_results = cross_val_score(model, x_all, y_all, cv=kf)\n",
        "\n",
        "print(f\"K-fold Results: {cross_val_results}\")\n",
        "print(f\"Mean Accuracy: {np.mean(cross_val_results)}\")"
      ],
      "id": "81cc9abf-3600-4e26-ac8e-3bab3fb58a86"
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "755d3525-12f8-4690-9b26-f052461632fa",
        "outputId": "8703f909-27d4-4919-eb50-7949b49d3ee9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "macro-averaged precision:  0.9452794774023008\n",
            "macro-averaged recall:  0.9430612720841962\n",
            "macro-averaged F1:  0.9440155381321169\n"
          ]
        }
      ],
      "source": [
        "show_marco_average_metrics(y_test, y_pred)"
      ],
      "id": "755d3525-12f8-4690-9b26-f052461632fa"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data processing and Feature selection (Adding third feature)"
      ],
      "metadata": {
        "id": "3xKMiaq1A9If"
      },
      "id": "3xKMiaq1A9If"
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "69d2409e-4424-47c3-ae95-c2df6697986c"
      },
      "outputs": [],
      "source": [
        "x_all=[]\n",
        "y_all=[]\n",
        "\n",
        "for entry in raw_data:\n",
        "    # Feature 1: Word frequency\n",
        "    vector_pos=get_vector_text(vocabulary, entry[0])\n",
        "    # Feature 2: Word count of the text file\n",
        "    word_count = len(get_list_tokens(entry[0]))\n",
        "    features = np.append(vector_pos, word_count)\n",
        "    # Feature 3: Named Entity recognition label count\n",
        "    entity_count = count_entity(entry[0])\n",
        "    features = np.append(features, entity_count)\n",
        "    x_all.append(features)\n",
        "    y_all.append(entry[1])"
      ],
      "id": "69d2409e-4424-47c3-ae95-c2df6697986c"
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32dd98f4-613f-49b4-9d3b-bc81695afdca",
        "outputId": "8bf283ef-65a1-48ee-ede5-b15fbf8c2e2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature index 1000 is already selected by SelectKBest()\n",
            "Feature index 1001 is already selected by SelectKBest()\n",
            "Feature index 1002 is already selected by SelectKBest()\n",
            "Feature index 1003 is already selected by SelectKBest()\n",
            "Feature index 1004 is already selected by SelectKBest()\n",
            "Feature index 1005 is already selected by SelectKBest()\n",
            "Size original training matrix: (1335, 1006)\n",
            "Size new training matrix: (1335, 500)\n"
          ]
        }
      ],
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    x_all, y_all, test_size=0.4\n",
        "    )\n",
        "\n",
        "x_train_sentanalysis = np.asarray(x_train)\n",
        "y_train_sentanalysis = np.asarray(y_train)\n",
        "x_test = np.asarray(x_test)\n",
        "y_test = np.asarray(y_test)\n",
        "\n",
        "fs_sentanalysis=SelectKBest(\n",
        "    chi2, k=500\n",
        "    ).fit(x_train_sentanalysis, y_train_sentanalysis)\n",
        "\n",
        "# Force keep the manually added features\n",
        "selected_indices = fs_sentanalysis.get_support(indices=True)\n",
        "\n",
        "for i in range(1000, 1006):\n",
        "    if i not in selected_indices:\n",
        "        print(f\"Adding the feature with index {str(i)}\")\n",
        "        selected_indices = np.concatenate([selected_indices, [i]])\n",
        "    else:\n",
        "        print(f\"Feature index {str(i)} is already selected by SelectKBest()\")\n",
        "\n",
        "x_train_sentanalysis_new = x_train_sentanalysis[:, selected_indices]\n",
        "x_test_new = x_test[:, selected_indices]\n",
        "\n",
        "print (\"Size original training matrix: \"+str(x_train_sentanalysis.shape))\n",
        "print (\"Size new training matrix: \"+str(x_train_sentanalysis_new.shape))"
      ],
      "id": "32dd98f4-613f-49b4-9d3b-bc81695afdca"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training and Predicting (With 3 features)"
      ],
      "metadata": {
        "id": "vuJRCX4PBdwh"
      },
      "id": "vuJRCX4PBdwh"
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "95de4f5c-b4d1-423c-9a19-a51a97408e6d",
        "outputId": "71560dde-a2c3-435c-c9d7-b48805532e52"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(gamma='auto', kernel='linear')"
            ],
            "text/html": [
              "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(gamma=&#x27;auto&#x27;, kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(gamma=&#x27;auto&#x27;, kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "model = sklearn.svm.SVC(kernel=\"linear\",gamma='auto')\n",
        "model.fit(x_train_sentanalysis_new,y_train_sentanalysis)"
      ],
      "id": "95de4f5c-b4d1-423c-9a19-a51a97408e6d"
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cc30827-b8f3-4545-bff9-fb909f92b29a",
        "outputId": "3b65c1b0-f583-4c44-af97-1188106c7803"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9359550561797753\n"
          ]
        }
      ],
      "source": [
        "y_pred = model.predict(x_test_new)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "id": "9cc30827-b8f3-4545-bff9-fb909f92b29a"
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4d271a41-de00-44c3-ab91-11d2244ae31b",
        "outputId": "07f509ad-8431-469c-ab9f-fd115e5ef124"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "K-fold Results: [0.95067265 0.95515695 0.95515695 0.95964126 0.93273543 0.98198198\n",
            " 0.97297297 0.95495495 0.96396396 0.96846847]\n",
            "Mean Accuracy: 0.9595705571041895\n"
          ]
        }
      ],
      "source": [
        "kf = KFold(n_splits=10, shuffle=True)\n",
        "cross_val_results = cross_val_score(model, x_all, y_all, cv=kf)\n",
        "\n",
        "print(f\"K-fold Results: {cross_val_results}\")\n",
        "print(f\"Mean Accuracy: {np.mean(cross_val_results)}\")"
      ],
      "id": "4d271a41-de00-44c3-ab91-11d2244ae31b"
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84d402e4-4036-49ca-953d-b7f6e3a3a635",
        "outputId": "61d3ecf5-b3cb-4b0d-f1be-5b3c880e9d34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "macro-averaged precision:  0.9365558055805581\n",
            "macro-averaged recall:  0.9342966365121038\n",
            "macro-averaged F1:  0.9348339174901803\n"
          ]
        }
      ],
      "source": [
        "show_marco_average_metrics(y_test, y_pred)"
      ],
      "id": "84d402e4-4036-49ca-953d-b7f6e3a3a635"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}